{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Reference\n> Vivek Srinivasan's EDA & Ensemble Model (Top 10 Percentile)\n> https://www.kaggle.com/viveksrinivasan/eda-ensemble-model-top-10-percentile"},{"metadata":{"trusted":true,"_uuid":"ceb7a03c52a3090ca15cd6a1dbacbcfe4414674d"},"cell_type":"code","source":"\"\"\"\nBike Sharing Demand 진행방향\n1) 훈련, 테스트 데이터셋의 형태 및 컬럼의 속성 데이터 값 파악\n2) 데이터 전처리 및 시각화\n3) 회귀모델 적용\n4) 결론 도출\n\n함수 사용시 꿀팁\n\n함수를 적용 시 내부 파라미터들을 모를 때 Anaconda Prompt or Windows PowerShell을 활용하여 내부의 REPL python 명령창에서\nex)) pandas.to_numeric() 함수의 내부 parameter를 알고 싶다면\nhelp(pandas.to_numeric)하게 되면, 함수의 사용법 등 문서를 열람할 수 있음\n=> 제가 굉장히 많이 씁니다!!\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"필요 라이브러리들 호출\"\"\"\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns #시각화를 위한 라이브러리\nimport matplotlib.pyplot as plt\nimport calendar \nfrom datetime import datetime\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\"\"\"\n1) 훈련, 테스트 데이터셋의 개괄적인 형태 및 데이터의 컬럼의 속성 및 값의 개수 파악\n\"\"\"\n\n#훈련데이터와 테스트 데이터 세트를 불러온다\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5eb3c11406e7cb9b2089adb9e66a4aeec1c60af"},"cell_type":"code","source":"#훈련데이터 셋의 개괄적인 모형 파악\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e9e06fa006e9b495486dba7068fd438ea6c681c"},"cell_type":"code","source":"#데이터 셋 내에 있는 컬럼 속성들에 대한 설명\n\n\"\"\"\ndatetime - hourly date + timestamp  \nseason -  1 = spring, 2 = summer, 3 = fall, 4 = winter \nholiday - whether the day is considered a holiday\nworkingday - whether the day is neither a weekend nor holiday\nweather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \ntemp - temperature in Celsius\natemp - \"feels like\" temperature in Celsius\nhumidity - relative humidity\nwindspeed - wind speed\ncasual - number of non-registered user rentals initiated\nregistered - number of registered user rentals initiated\ncount - number of total rentals\n\"\"\"\n\n#훈련 데이터셋의 각 컬럼별 데이터타입 및 값의 갯수 파악\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80d3b7be58a3c71c1c10ff6cb850dd43d8acac23"},"cell_type":"code","source":"#테스트 데이터 셋의 개괄적인 형태 출력\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c68e836978ee486cb8047253d3cbfdac02e20b2f"},"cell_type":"code","source":"\"\"\" 2) 데이터 전처리 및 시각화 \"\"\"\n\n#datetime속성을 분리하여 추출속성으로 활용하기 위해 split함수를 사용하여 년-월-일 과 시간을 분리한다.\ntrain['tempDate'] = train.datetime.apply(lambda x:x.split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1ba01c6f0dfe37eb04bde4b7a0aca32c469c60c"},"cell_type":"code","source":"#분리한 tempDate를 가지고 년-월-일을 이용하여 year,month,day 그리고 weekday column을 추출한다.\n# split() 내장함수 설명: https://wikidocs.net/13 [문자형 자료형_ 문자열 나누기] <=> join() [문자형 자료형_ 문자열 삽입]\ntrain['year'] = train.tempDate.apply(lambda x:x[0].split('-')[0])\ntrain['month'] = train.tempDate.apply(lambda x:x[0].split('-')[1])\ntrain['day'] = train.tempDate.apply(lambda x:x[0].split('-')[2])\n#weekday는 calendar패키지와 datetime패키지를 활용한다.\n#calendar.day_name 사용법 : https://stackoverflow.com/questions/36341484/get-day-name-from-weekday-int\n#datetime.strptime 문서: https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n#파이썬에서 날짜와 시간 다루기: https://datascienceschool.net/view-notebook/465066ac92ef4da3b0aba32f76d9750a/ \ntrain['weekday'] = train.tempDate.apply(lambda x:calendar.day_name[datetime.strptime(x[0],\"%Y-%m-%d\").weekday()])\n\ntrain['hour'] = train.tempDate.apply(lambda x:x[1].split(':')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"371c25defab1ecd2a33c4a237c51986a9fd646a9"},"cell_type":"code","source":"#분리를 통해 추출된 속성은 문자열 속성을 가지고 있음 따라서 숫자형 데이터로 변환해 줄 필요가 있음.\n#pandas.to_numeric(): https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_numeric.html\ntrain['year'] = pd.to_numeric(train.year,errors='coerce')\ntrain['month'] = pd.to_numeric(train.month,errors='coerce')\ntrain['day'] = pd.to_numeric(train.day,errors='coerce')\ntrain['hour'] = pd.to_numeric(train.hour,errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44e6e12df6dbb8b7aa2c04d52200455317f6e7e7","scrolled":true},"cell_type":"code","source":"#year,month,day,hour가 숫자형으로 변환되었음을 알 수 있음.\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad68bbb97bd33831e5d8c120ba58a37cde8c81df"},"cell_type":"code","source":"#필요를 다한 tempDate column을 drop함\ntrain = train.drop('tempDate',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec06afd0cbcb0a92f24191e77c6403bdd57dbda0"},"cell_type":"code","source":"#각각의 속성과 예측의 결과값으로 쓰이는 count값과의 관계 파악\n\n#년도와 count\nfig = plt.figure(figsize=[12,10])\nax1 = fig.add_subplot(2,2,1)\nax1 = sns.barplot(x='year',y='count',data=train.groupby('year')['count'].mean().reset_index())\n\n#month와 count\nax2 = fig.add_subplot(2,2,2)\nax2 = sns.barplot(x='month',y='count',data=train.groupby('month')['count'].mean().reset_index())\n\n#day와 count\nax3 = fig.add_subplot(2,2,3)\nax3 = sns.barplot(x='day',y='count',data=train.groupby('day')['count'].mean().reset_index())\n\n#hour와 count\nax4 = fig.add_subplot(2,2,4)\nax4 = sns.barplot(x='hour',y='count',data=train.groupby('hour')['count'].mean().reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ef611d193d04eb01188fcebcbb824a984f0f586"},"cell_type":"code","source":"#계절과 count\nfig = plt.figure(figsize=[12,10])\nax1 = fig.add_subplot(2,2,1)\nax1 = sns.barplot(x='season',y='count',data=train.groupby('season')['count'].mean().reset_index())\n\n#휴일 여부와 count\nax2 = fig.add_subplot(2,2,2)\nax2 = sns.barplot(x='holiday',y='count',data=train.groupby('holiday')['count'].mean().reset_index())\n\n#작업일 여부와 count\nax3 = fig.add_subplot(2,2,3)\nax3 = sns.barplot(x='workingday',y='count',data=train.groupby('workingday')['count'].mean().reset_index())\n\n#날씨와 count\nax4 = fig.add_subplot(2,2,4)\nax4 = sns.barplot(x='weather',y='count',data=train.groupby('weather')['count'].mean().reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0947fe2fd1fdaabc45431e0572c6c0d834d01145"},"cell_type":"code","source":"\"\"\"\n해당 부분은 필자가 스스로 데이터를 보고 이상함을 느껴 전처리함.\n왜냐하면, 처음 import한 데이터 셋에서 head()를 하였을 때 1월1일의 season column은 1 즉 봄을 가르키는데,\n직접 3월에 washington을 직접 가본 결과 1월은 확실히 겨울이다.\n따라서 아래의 badToRight를 이용하여 season column을 수정하고자 했음.\n이 데이터 때문에 참조했던 커널과는 다른 정확도를 나타낼 수 있음.\n\"\"\"\n\ndef badToRight(month):\n    if month in [12,1,2]:\n        return 4\n    elif month in [3,4,5]:\n        return 1\n    elif month in [6,7,8]:\n        return 2\n    elif month in [9,10,11]:\n        return 3\n\n#apply() 내장함수는 split(),map(),join(),filter()등 과 함꼐 필수적으로 숙지해야 할 함수이다.\ntrain['season'] = train.month.apply(badToRight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"229c4158aa2ca27a1e495fc1c7724b5d4a8eee2b"},"cell_type":"code","source":"#위의 시각화와 같이 하나의 컬럼과 결과 값을 비교해보자\n\n#계절과 count\nfig = plt.figure(figsize=[12,10])\nax1 = fig.add_subplot(2,2,1)\nax1 = sns.barplot(x='season',y='count',data=train.groupby('season')['count'].mean().reset_index())\n\n#휴일 여부와 count\nax2 = fig.add_subplot(2,2,2)\nax2 = sns.barplot(x='holiday',y='count',data=train.groupby('holiday')['count'].mean().reset_index())\n\n#작업일 여부와 count\nax3 = fig.add_subplot(2,2,3)\nax3 = sns.barplot(x='workingday',y='count',data=train.groupby('workingday')['count'].mean().reset_index())\n\n#날씨와 count\nax4 = fig.add_subplot(2,2,4)\nax4 = sns.barplot(x='weather',y='count',data=train.groupby('weather')['count'].mean().reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a59e095f81cd58e67d59021ac45668157e088fd"},"cell_type":"code","source":"#그리고 남은 분포를 통해 표현하였을 때 좋은 컬럼들을 count와 비교해보자\n\n#온도와 count\nfig = plt.figure(figsize=[12,10])\nax1 = fig.add_subplot(2,2,1)\nax1 = sns.distplot(train.temp,bins=range(train.temp.min().astype('int'),train.temp.max().astype('int')+1))\n\n#평균온도와 count\nax2 = fig.add_subplot(2,2,2)\nax2 = sns.distplot(train.atemp,bins=range(train.atemp.min().astype('int'),train.atemp.max().astype('int')+1))\n\n#습도와 count\nax3 = fig.add_subplot(2,2,3)\nax3 = sns.distplot(train.humidity,bins=range(train.humidity.min().astype('int'),train.humidity.max().astype('int')+1))\n\n#바람속도와 count\nax4 = fig.add_subplot(2,2,4)\nax4 = sns.distplot(train.windspeed,bins=range(train.windspeed.min().astype('int'),train.windspeed.max().astype('int')+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ba3221a770584cc3f8997af4ad80f87b659209b"},"cell_type":"code","source":"#각각의 컬럼들 간의 상관계수를 heatmap을 통해 시각화\n\nfig = plt.figure(figsize=[20,20])\nax = sns.heatmap(train.corr(),annot=True,square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62a06b8f4bfdb1cb57b6eda57ac873c7f3fb805a"},"cell_type":"code","source":"#heatmap 상관관계를 참조하여 이전의 시각화와는 달리 두 개의 서로다른 컬럼이 적용된 count를 시각화해보자\n\n#시간과 계절에 따른 count\nfig = plt.figure(figsize=[12,10])\nax1 = fig.add_subplot(2,2,1)\nax1 = sns.pointplot(x='hour',y='count',hue='season',data=train.groupby(['season','hour'])['count'].mean().reset_index())\n\n#시간과 휴일 여부에 따른 count\nax2 = fig.add_subplot(2,2,2)\nax2 = sns.pointplot(x='hour',y='count',hue='holiday',data=train.groupby(['holiday','hour'])['count'].mean().reset_index())\n\n#시간과 휴일 여부에 따른 count\nax3 = fig.add_subplot(2,2,3)\nax3 = sns.pointplot(x='hour',y='count',hue='weekday',hue_order=['Sunday','Monday','Tuesday','Wendnesday','Thursday','Friday','Saturday'],data=train.groupby(['weekday','hour'])['count'].mean().reset_index())\n\n#시간과 날씨에 따른 count\nax4 = fig.add_subplot(2,2,4)\nax4 = sns.pointplot(x='hour',y='count',hue='weather',data=train.groupby(['weather','hour'])['count'].mean().reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f92e2e3eaeaf5b368377ebe5d7479fc6ab702be7"},"cell_type":"code","source":"#마지막 시각화에 이상치가 있는 것같아서 확인\n\ntrain[train.weather==4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"ca58b084ac9768e7e04295f8361b7af11fa48397"},"cell_type":"code","source":"#달과 날씨에 따른 count \nfig = plt.figure(figsize=[12,10])\nax1 = fig.add_subplot(2,1,1)\nax1 = sns.pointplot(x='month',y='count',hue='weather',data=train.groupby(['weather','month'])['count'].mean().reset_index())\n\n#달별 count\nax2 = fig.add_subplot(2,1,2)\nax2 = sns.barplot(x='month',y='count',data=train.groupby('month')['count'].mean().reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f862e6aa2e0097bb157dfea8528d0d5bc27e173d"},"cell_type":"code","source":"\"\"\"\nWindspeed 분포를 표현한 그래프에서 Windspeed가 0인 값들이 많았는데,\n이는 실제로 0이었던지 or 값을 제대로 측정하지 못해서 0인지 두 개의 경우가 있다.\n하지만 후자의 생각을 가지고 우리의 데이터를 활용하여 windspeed값을 부여해보자\n\"\"\"\n\n#머신러닝 모델에 훈련시킬 때는 문자열 값은 불가능하기 때문에 문자열을 카테고리화 하고 각각에 해당하는 값을 숫자로 변환해준다\ntrain['weekday']= train.weekday.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f453a931c1c082addc0887ee8bfeca83a3d83777"},"cell_type":"code","source":"print(train['weekday'].cat.categories)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b41d7f46305232783b8db4c5bd797ccc6e3de8c"},"cell_type":"code","source":"#0:Sunday --> 6:Saturday\ntrain.weekday.cat.categories = ['5','1','6','0','4','2','3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b14045f7330ba88a92bfa0a39258fdcb376f77ba"},"cell_type":"code","source":"\"\"\"\nRandomForest를 활용하여 Windspeed값을 부여해보자\n하나의 데이터를 Windspeed가 0인 그리고 0이 아닌 데이터프레임으로 분리하고\n학습시킬 0이 아닌 데이터 프레임에서는 Windspeed만 담긴 Series와 이외의 학습시킬 column들의 데이터프레임으로 분리한다\n학습 시킨 후에 Windspeed가 0인 데이터 프레임에서 학습시킨 컬럼과 같게 추출하여 결과 값을 부여받은 후,\nWindspeed가 0인 데이터프레임에 Windspeed값을 부여한다.\n\"\"\"\nfrom sklearn.ensemble import RandomForestRegressor\n\n#Windspeed가 0인 데이터프레임\nwindspeed_0 = train[train.windspeed == 0]\n#Windspeed가 0이 아닌 데이터프레임\nwindspeed_Not0 = train[train.windspeed != 0]\n\n#Windspeed가 0인 데이터 프레임에 투입을 원치 않는 컬럼을 배제\nwindspeed_0_df = windspeed_0.drop(['windspeed','casual','registered','count','datetime'],axis=1)\n\n#Windspeed가 0이 아닌 데이터 프레임은 위와 동일한 데이터프레임을 형성하고 학습시킬 Windspeed Series를 그대로 둠\nwindspeed_Not0_df = windspeed_Not0.drop(['windspeed','casual','registered','count','datetime'],axis=1)\nwindspeed_Not0_series = windspeed_Not0['windspeed'] \n\n#모델에 0이 아닌 데이터프레임과 결과값을 학습\nrf = RandomForestRegressor()\nrf.fit(windspeed_Not0_df,windspeed_Not0_series)\n#학습된 모델에 Windspeed가 0인 데이터프레임의 Windspeed를 도출\npredicted_windspeed_0 = rf.predict(windspeed_0_df)\n#도출된 값을 원래의 데이터프레임에 삽입\nwindspeed_0['windspeed'] = predicted_windspeed_0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e824b8dc127e4c6566e5bf3a1f50a15cdae3b217"},"cell_type":"code","source":"#나눈 데이터 프레임을 원래의 형태로 복원\ntrain = pd.concat([windspeed_0,windspeed_Not0],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae353b4bc9e4960b5fc7e226a3a0f310d368d65c"},"cell_type":"code","source":"#시간별 정렬을 위해 string type의 datetime을 datetime으로 변환\ntrain.datetime = pd.to_datetime(train.datetime,errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74cac1e66dbd6f198b36039535c8fcdbea03d5ff"},"cell_type":"code","source":"#합쳐진 데이터를 datetime순으로 정렬\ntrain = train.sort_values(by=['datetime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee00fe320b4ae389240bd63cc8aafdc166b8c80d"},"cell_type":"code","source":"#windspeed를 수정한 후 다시 상관계수를 분석\n#우리의 기대와는 달리 windspeed와 count의 상관관계는 0.1에서 0.11로 간소한 차이만 보임.\nfig = plt.figure(figsize=[20,20])\nax = sns.heatmap(train.corr(),annot=True,square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e7641dadd9fd46e949c635c671fb1d02a55c8d4"},"cell_type":"code","source":"fig = plt.figure(figsize=[5,5])\nsns.distplot(train['windspeed'],bins=np.linspace(train['windspeed'].min(),train['windspeed'].max(),10))\nplt.suptitle(\"Filled by Random Forest Regressor\")\nprint(\"Min value of windspeed is {}\".format(train['windspeed'].min()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e9de667bafac554c68e22dc9faf2658dd7c6fe6"},"cell_type":"code","source":"\"\"\"이제 모든 동일한 전처리 과정을 test셋과 한꺼번에 진행\"\"\"\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"789193ae5108eb1109c78cd9f6651e3ba3a51cf4"},"cell_type":"code","source":"combine = pd.concat([train,test],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1cdcd645f1ef2ee4a25a5174a68699be8b97bdf1"},"cell_type":"code","source":"combine.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5381e0ff75eb484b06b22a6fd61a6ca43dc74a12"},"cell_type":"code","source":"combine['tempDate'] = combine.datetime.apply(lambda x:x.split())\ncombine['weekday'] = combine.tempDate.apply(lambda x: calendar.day_name[datetime.strptime(x[0],\"%Y-%m-%d\").weekday()])\ncombine['year'] = combine.tempDate.apply(lambda x: x[0].split('-')[0])\ncombine['month'] = combine.tempDate.apply(lambda x: x[0].split('-')[1])\ncombine['day'] = combine.tempDate.apply(lambda x: x[0].split('-')[2])\ncombine['hour'] = combine.tempDate.apply(lambda x: x[1].split(':')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86be1dc65c30c8868ee32eb10f86b496bab16bbc"},"cell_type":"code","source":"combine['year'] = pd.to_numeric(combine.year,errors='coerce')\ncombine['month'] = pd.to_numeric(combine.month,errors='coerce')\ncombine['day'] = pd.to_numeric(combine.day,errors='coerce')\ncombine['hour'] = pd.to_numeric(combine.hour,errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"837e50c68bfaeb090d13fe1a864d8404e1a38d72"},"cell_type":"code","source":"combine.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bb200d47d96c621e1928d51ed776892e81c34a4"},"cell_type":"code","source":"combine['season'] = combine.month.apply(badToRight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f2746c63207641536a70bdf4bd4a86cf76a9be9"},"cell_type":"code","source":"combine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ffb543ce8ebdbaa0b015776067438eb02296d9e"},"cell_type":"code","source":"combine.weekday = combine.weekday.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d098e9042587fca6b6f0bffb305423c60d62a7f"},"cell_type":"code","source":"combine.weekday.cat.categories = ['5','1','6','0','4','2','3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b34971af7e5798745d3bc3651d16f2732cda7e86"},"cell_type":"code","source":"dataWind0 = combine[combine['windspeed']==0]\ndataWindNot0 = combine[combine['windspeed']!=0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecdabedf6d8e14e394326bbd688bbfc2629f38d7"},"cell_type":"code","source":"dataWind0.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1172273626dd9a0feee9b7f0d082551319f7b0f0"},"cell_type":"code","source":"dataWind0_df = dataWind0.drop(['windspeed','casual','registered','count','datetime','tempDate'],axis=1)\n\ndataWindNot0_df = dataWindNot0.drop(['windspeed','casual','registered','count','datetime','tempDate'],axis=1)\ndataWindNot0_series = dataWindNot0['windspeed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70a79947275929262abd2fec67fd266349604b05"},"cell_type":"code","source":"dataWindNot0_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e481801dac44a8812e8f22243ee503bbbf3dd0ab"},"cell_type":"code","source":"dataWind0_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42f4e4759c6a0f38b312733df5a8ceef80803632"},"cell_type":"code","source":"rf2 = RandomForestRegressor()\nrf2.fit(dataWindNot0_df,dataWindNot0_series)\npredicted = rf2.predict(dataWind0_df)\nprint(predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3dbcc601d0b9704c52e5e5e376a5a13b4728894"},"cell_type":"code","source":"dataWind0['windspeed'] = predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff9bc99b8e4cf8c77e352afe9ab133b267758daa"},"cell_type":"code","source":"combine = pd.concat([dataWind0,dataWindNot0],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a21878561f0b6fe3c726e5def275521fcfdbb804"},"cell_type":"code","source":"#우리가 가진 column들 중 값들이 일정하고 정해져있다면 category로 변경해주고\n#필요하지 않은 column들은 이제 버린다.\ncategorizational_columns = ['holiday','humidity','season','weather','workingday','year','month','day','hour']\ndrop_columns = ['datetime','casual','registered','count','tempDate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52c23fa5960a71da5ea922dad486c2bbbb197d8f"},"cell_type":"code","source":"#categorical하게 변환\nfor col in categorizational_columns:\n    combine[col] = combine[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b80bd944a4d669691ef27ebff490a4cce76c9c49"},"cell_type":"code","source":"#합쳐진 combine데이터 셋에서 count의 유무로 훈련과 테스트셋을 분리하고 각각을 datetime으로 정렬\ntrain = combine[pd.notnull(combine['count'])].sort_values(by='datetime')\ntest = combine[~pd.notnull(combine['count'])].sort_values(by='datetime')\n\n#데이터 훈련시 집어 넣게 될 각각의 결과 값들\ndatetimecol = test['datetime']\nyLabels = train['count'] #count\nyLabelsRegistered = train['registered'] #등록된 사용자\nyLabelsCasual = train['casual'] #임시 사용자","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3572c857cb3e0bc59291e41a8a1b69ad0f2c89b1"},"cell_type":"code","source":"#필요 없는 column들을 버린 후의 훈련과 테스트 셋\ntrain = train.drop(drop_columns,axis=1)\ntest = test.drop(drop_columns,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"080ed790f6a493e2f785e60e27bc30cbeef8c32a"},"cell_type":"code","source":"\"\"\"\n해당 문제에서는 RMSLE방식을 이용하여 제대로 예측이 되었는지 평가하게 됨.\nRMSLE는 아래 링크를 참조하여 이용.\nhttps://programmers.co.kr/learn/courses/21/lessons/943#\n\nRMSLE\n과대평가 된 항목보다는 과소평가 된 항목에 페널티를 주는방식\n오차를 제곱하여 형균한 값의 제곱근으로 값이 작아질 수록 정밀도가 높음\n0에 가까운 값이 나올 수록 정밀도가 높다\n\"\"\"\n\n# y is predict value y_ is actual value\ndef rmsle(y, y_,convertExp=True):\n    if convertExp:\n        y = np.exp(y), \n        y_ = np.exp(y_)\n    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n    calc = (log1 - log2) ** 2\n    return np.sqrt(np.mean(calc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa245e1a98670ca93ab82dc47278c2e81041c74c"},"cell_type":"code","source":"#선형 회귀 모델\n#선형 회귀모델은 건드릴 만한 내부 attr들이 없음\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\n\n\nlr = LinearRegression()\n\n\"\"\"\n아래의 커널을 참조하여 yLabels를 로그화 하려는데 왜 np.log가 아닌 np.log1p를 활용하는가??\nnp.log1p는 np.log(1+x)와 동일. 이유는 만약 어떤 x값이 0인데 이를 log하게되면, (-)무한대로 수렴하기 때문에 np.log1p를 활용함. \n참조: https://ko.wikipedia.org/wiki/%EB%A1%9C%EA%B7%B8 \n\"\"\"\nyLabelslog = np.log1p(yLabels)\n#선형 모델에 우리의 데이터를 학습\nlr.fit(train,yLabelslog)\n#결과 값 도출\npreds = lr.predict(train)\n#rmsle함수의 element에 np.exp()지수 함수를 취하는 이유는 우리의 preds값에 얻어진 것은 한번 log를 한 값이기 때문에 원래 모델에는 log를 하지 않은 원래의 값을 넣기 위함임.\nprint('RMSLE Value For Linear Regression: {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a63b098e9b24129fb96143f1d25cc6d707b77c8"},"cell_type":"code","source":"\"\"\"\n데이터 훈련시 Log값을 취하는 이유??\n우리가 결과 값으로 투입하는 Count값이 최저 값과 최고 값의 낙폭이 너무 커서\n만약 log를 취하지 않고 해보면 print하는 결과 값이 inf(infinity)로 뜨게 됨\n\"\"\"\n\n#count값의 분포\nsns.distplot(yLabels,bins=range(yLabels.min().astype('int'),yLabels.max().astype('int')))\n\n#기존 훈련 데이터셋의 count의 개수\nprint(yLabels.count()) #10886\n\n\"\"\" \n3 sigma를 활용한 이상치 확인\n참조 : https://ko.wikipedia.org/wiki/68-95-99.7_%EA%B7%9C%EC%B9%99\n\"\"\"\n#3시그마를 적용한 이상치를 배제한 훈련 데이터셋의 count의 개수\nyLabels[np.logical_and(yLabels.mean()-3*yLabels.std() <= yLabels,yLabels.mean()+3*yLabels.std() >= yLabels)].count() #10739\n#이상치들이 존재할 때는 log를 활용하여 값을 도출","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f5803c978c310a1de3ce0e74df0d034a002dd1f","scrolled":true},"cell_type":"code","source":"\"\"\"\nGridSearchCV를 활용하면 우리가 이용하게 될 각각의 모델마다 변경해야 하는 파라미터 튜닝시 어떤 파라미터가 최적의 값을 내는지 등을 알 수 있음.\n\nGridSearchCV 참조:\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\nhttps://datascienceschool.net/view-notebook/ff4b5d491cc34f94aea04baca86fbef8/\n\"\"\"\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\n\n#Ridge모델은 L2제약을 가지는 선형회귀모델에서 개선된 모델이며 해당 모델에서 유의 깊게 튜닝해야하는 파라미터는 alpha값이다.\nridge = Ridge()\n\n#우리가 튜닝하고자하는 Ridge의 파라미터 중 특정 파라미터에 배열 값으로 넘겨주게 되면 테스트 후 어떤 파라미터가 최적의 값인지 알려줌 \nridge_params = {'max_iter':[3000],'alpha':[0.001,0.01,0.1,1,10,100,1000]}\nrmsle_scorer = metrics.make_scorer(rmsle,greater_is_better=False)\ngrid_ridge = GridSearchCV(ridge,ridge_params,scoring=rmsle_scorer,cv=5)\n\ngrid_ridge.fit(train,yLabelslog)\npreds = grid_ridge.predict(train)\nprint(grid_ridge.best_params_)\nprint('RMSLE Value for Ridge Regression {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9202f8fa25a70f1ae5b9f478704cfe5da76a678","scrolled":false},"cell_type":"code","source":"#결과에 대해 GridSearchCV의 변수인 grid_ridge변수에 cv_result_를 통해 alpha값의 변화에 따라 평균값의 변화를 파악 가능\ndf = pd.DataFrame(grid_ridge.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2451a3f21ed4d2e66d60ad21531c63401f2ced4f"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee63bde1b06b65961f1be5240b0974e461b0ea6e"},"cell_type":"code","source":"#Ridge모델은 L1제약을 가지는 선형회귀모델에서 개선된 모델이며 해당 모델에서 유의 깊게 튜닝해야하는 파라미터는 alpha값이다.\nlasso = Lasso()\n\nlasso_params = {'max_iter':[3000],'alpha':[0.001,0.01,0.1,1,10,100,1000]}\ngrid_lasso = GridSearchCV(lasso,lasso_params,scoring=rmsle_scorer,cv=5)\ngrid_lasso.fit(train,yLabelslog)\npreds = grid_lasso.predict(train)\nprint('RMSLE Value for Lasso Regression {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11a46901f3eb37acaf3b8e2ed03a048798ee8733"},"cell_type":"code","source":"rf = RandomForestRegressor()\n\nrf_params = {'n_estimators':[1,10,100]}\ngrid_rf = GridSearchCV(rf,rf_params,scoring=rmsle_scorer,cv=5)\ngrid_rf.fit(train,yLabelslog)\npreds = grid_rf.predict(train)\nprint('RMSLE Value for RandomForest {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dd69246cb973a312c15e6a20bcc84fac5a90c0f"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngb = GradientBoostingRegressor()\ngb_params={'max_depth':range(1,11,1),'n_estimators':[1,10,100]}\ngrid_gb=GridSearchCV(gb,gb_params,scoring=rmsle_scorer,cv=5)\ngrid_gb.fit(train,yLabelslog)\npreds = grid_gb.predict(train)\nprint('RMSLE Value for GradientBoosting {}'.format(rmsle(np.exp(yLabelslog),np.exp(preds),False)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e4d16f0b8e968fa79f48688bdd7de6c34c16c62"},"cell_type":"code","source":"predsTest = grid_gb.predict(test)\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsns.distplot(yLabels,ax=ax1,bins=50)\nsns.distplot(np.exp(predsTest),ax=ax2,bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e284cee10d8ccb91a78e5670344826d5a914c309"},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"datetime\": datetimecol,\n        \"count\": [max(0, x) for x in np.exp(predsTest)]\n    })\nsubmission.to_csv('bike_predictions_gbm_separate_without_fe.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}